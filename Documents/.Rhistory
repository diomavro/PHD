names(monthlydata)[names(monthlydata) == "data$Product.Sales"] <- "monthlysales"
plot(monthlydata$monthlysales , type = "l", main = "Monthly", ylab = "monthlysales", xlab = "Date" )
plot(weeklydata$weekly , type = "l", main = "Weekly", ylab = "WeeklySales", xlab = "Date" )
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
plot(dec, type = "l", ylab = "Index", xlab = "Period")
#makemonthly
qdate = strftime(data$Date , "%Y/%m")
qmonthlydata = aggregate(data$Product.Sales ~ qdate, FUN = sum)
#rename
names(qmonthlydata)[names(qmonthlydata) == "qdate"] <- "Month"
names(qmonthlydata)[names(qmonthlydata) == "data$Product.Sales"] <- "monthlysales"
#visualize monthly
plot(qmonthlydata$monthlysales , type = "l", main = "Monthly", ylab = "monthlysales", xlab = "Date" )
#decompose monthly
TS <- ts(qmonthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#dec <- decompose(TS , type = c("additive", "multiplicative"))
plot(dec, type = "l", ylab = "Index", xlab = "Period")
install.packages("rmarkdown")
title: "Forecast_1"
author: "Diomides_Mavroyiannis"
date: "25/11/2020"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Loading the data
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
View(data)
#Preparing the library
library(forecast)
#Part A
# Visualize the Company sales column
plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
View(data)
`View(data)`
knitr::opts_chunk$set(echo = TRUE)
#Loading the data
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
`View(data)`
knitr::opts_chunk$set(echo = TRUE)
#Loading the data
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
View(data)
#Preparing the library
library(forecast)
#Part A
# Visualize the Company sales column
plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )
#missing values
#The approach here, is to check if a value is missing, if it is, then take the mean of the next and the previous period to fill it in.
#if the next slot is empty we simply take the average of two older slots
for (i in (frequency(data$Company.Sales)+1): (length(data$Company.Sales)-12)){
if (is.na(data$Company.Sales[i])==TRUE){
print(i)
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales)], data$Company.Sales[i+frequency(data$Company.Sales)]))
if (is.na(data$Company.Sales[i])==TRUE){
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales) ], data$Company.Sales[i-1 - frequency(data$Company.Sales)]))
}
}
}
#outliers
#We first compute the values where 95% and 5% of the data is above that
lowerlimit <- quantile(data$Company.Sales,0.95)
upperlimit <- quantile(data$Company.Sales,0.05)
#We create a new vector that will hold the series we will create
n_data1 <- data$Company.Sales
#We now replace the values which are above and below the limits calculated earlier by the 95% and 5% quantiles.
n_data1[n_data1>lowerlimit] <- lowerlimit
n_data1[n_data1<upperlimit] <- upperlimit
`plot(data$Company.Sales, type = "l", ylab = "Company sales", xlab = "year", main = "Company Sales")`
'plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )'
knitr::opts_chunk$set(echo = TRUE)
#Loading the data
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
View(data)
#Preparing the library
library(forecast)
#Part A
'plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )'
'plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )'
'plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )'
plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )
for (i in (frequency(data$Company.Sales)+1): (length(data$Company.Sales)-12)){
if (is.na(data$Company.Sales[i])==TRUE){
print(i)
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales)], data$Company.Sales[i+frequency(data$Company.Sales)]))
if (is.na(data$Company.Sales[i])==TRUE){
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales) ], data$Company.Sales[i-1 - frequency(data$Company.Sales)]))
}
}
}
for (i in (frequency(data$Company.Sales)+1): (length(data$Company.Sales)-12)){
if (is.na(data$Company.Sales[i])==TRUE){
print(i)
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales)], data$Company.Sales[i+frequency(data$Company.Sales)]))
if (is.na(data$Company.Sales[i])==TRUE){
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales) ], data$Company.Sales[i-1 - frequency(data$Company.Sales)]))
}
}
}
lowerlimit <- quantile(data$Company.Sales,0.95)
upperlimit <- quantile(data$Company.Sales,0.05)
#We create a new vector that will hold the series we will create
n_data1 <- data$Company.Sales
#We now replace the values which are above and below the limits calculated earlier by the 95% and 5% quantiles.
n_data1[n_data1>lowerlimit] <- lowerlimit
n_data1[n_data1<upperlimit] <- upperlimit
plot(data$Company.Sales, type = "l", ylab = "Company sales", xlab = "year", main = "Company Sales")
lines(n_data1, col = "red")
legend("center", legend = c("Original", "Trimmed"),col, c("black","red"),lty=1)
# Coerce to Date class(it says double)
data$Date <- as.Date(data$Date , format = '%d-%m-%Y')
# Extract day of the week (Saturday = 6)
data$Week_Day <- as.numeric(format(data$Date, format='%w'))
# Adjust end-of-week date (first saturday from the original Date)
data$End_of_Week <- data$Date + (6 - data$Week_Day)
# Aggregate over week and climate division
weeklydata <- aggregate(data$Company.Sales~data$End_of_Week, FUN=mean, data=data, na.rm=TRUE)
#makemonthly
short.date = strftime(data$Date , "%Y/%m")
monthlydata = aggregate(data$Company.Sales ~ short.date, FUN = sum)
#rename
names(weeklydata)[names(weeklydata) == "data$End_of_Week"] <- "Endofweek"
names(weeklydata)[names(weeklydata) == "data$Company.Sales"] <- "weekly"
names(monthlydata)[names(monthlydata) == "short.date"] <- "Month"
names(monthlydata)[names(monthlydata) == "data$Company.Sales"] <- "monthlysales"
plot(monthlydata$monthlysales , type = "l", main = "Monthly", ylab = "monthlysales", xlab = "Date" )
plot(weeklydata$weekly , type = "l", main = "Weekly", ylab = "WeeklySales", xlab = "Date" )
plot(dec, type = "l", ylab = "Index", xlab = "Period")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec1 <- decompose(TS , type = "additive")
plot(dec1, type = "l", ylab = "Index", xlab = "Period")
plot(dec1, type = "l", ylab = "Index", xlab = "Period")
plot(dec1, type = "l", ylab = "Index", xlab = "Period")
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec1 <- decompose(TS , type = "additive")
dec2 <- decompose(TS , type = "multiplicative")
plot(dec1, type = "l", ylab = "Index", xlab = "Period")
plot(dec2, type = "l", ylab = "Index", xlab = "Period")
e daily sale is `mean(data$Company.Sales)`
#The average daily sale is:
mean(data$Company.Sales)
#The average monthly sale is:
mean(monthlydata$monthlysales)
#visualize
plot(data$Product.Sales , type = "l", main = "Shopping", ylab = "Product.sales", xlab = "Date" )
#Average Daily demand
mean(data$Product.Sales)
#Coefficient of Variation
sd(data$Product.Sales[0<data$Product.Sales])*100/mean(data$Product.Sales[0<data$Product.Sales])
#Average Daily demand
mean(data$Product.Sales)
#Coefficient of Variation
sd(data$Product.Sales[0<data$Product.Sales])*100/mean(data$Product.Sales[0<data$Product.Sales])
#ADI
nonzero <- length(which(data$Product.Sales != 0))
zero <- length(which(data$Product.Sales != 0))
#the rate is:
rate <-zero/(nonzero+zero)
#So we inverse this to get the average expected days
Avgwait <- 1/rate
#ADI
nonzero <- length(which(data$Product.Sales != 0))
zero <- length(which(data$Product.Sales != 0))
#the rate is:
rate <-zero/(nonzero+zero)
#So we inverse this to get the average expected days
Avgwait <- 1/rate
#ADI
nonzero <- length(which(data$Product.Sales != 0))
zero <- length(which(data$Product.Sales != 0))
#the rate is:
rate <-zero/(nonzero+zero)
#So we inverse this to get the average expected days
Avgwait <- 1/rate
Avgwait
plot(data$Product.Sales , type = "l", ylab = "Quantity", xlab = "days", main = "Sold product")
library(fpp)
plot(data$Product.Sales , type = "l", ylab = "Quantity", xlab = "days", main = "Sold product")
par(mfrow = c(1,3))
boxplot(data$Product.Sales, main = "Boxplot Quantity" )
hist(data$Product.Sales )
plot(density(data$Product.Sales), main = "Kernel Density of Quantity")
plot(data$Product.Sales , type = "l", ylab = "Quantity", xlab = "days", main = "Sold product")
par(mfrow = c(1,3))
boxplot(data$Product.Sales, main = "Boxplot Quantity" )
hist(data$Product.Sales )
plot(density(data$Product.Sales), main = "Kernel Density of Quantity")
density(data$Product.Sales)
quantile(data$Product.Sales,0.05)
quantile(data$Product.Sales,0.5)
quantile(data$Product.Sales,0.95)
#makemonthly
qdate = strftime(data$Date , "%Y/%m")
qmonthlydata = aggregate(data$Product.Sales ~ qdate, FUN = sum)
#rename
names(qmonthlydata)[names(qmonthlydata) == "qdate"] <- "Month"
names(qmonthlydata)[names(qmonthlydata) == "data$Product.Sales"] <- "monthlysales"
#makemonthly
qdate = strftime(data$Date , "%Y/%m")
qmonthlydata = aggregate(data$Product.Sales ~ qdate, FUN = sum)
#rename
names(qmonthlydata)[names(qmonthlydata) == "qdate"] <- "Month"
names(qmonthlydata)[names(qmonthlydata) == "data$Product.Sales"] <- "monthlysales"
#visualize monthly
plot(qmonthlydata$monthlysales , type = "l", main = "Monthly", ylab = "monthlysales", xlab = "Date" )
#decompose monthly
TS <- ts(qmonthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#dec <- decompose(TS , type = c("additive", "multiplicative"))
plot(dec, type = "l", ylab = "Index", xlab = "Period")
knitr::opts_chunk$set(echo = TRUE)
#Loading the data
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
View(data)
#Preparing the library
library(forecast)
#Part A
plot(pressure)
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
View(data)
#Preparing the library
library(forecast)
#Part A
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
View(data)
#Preparing the library
library(forecast)
#Part A
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
#Preparing the library
library(forecast)
#Part A
plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )
for (i in (frequency(data$Company.Sales)+1): (length(data$Company.Sales)-12)){
if (is.na(data$Company.Sales[i])==TRUE){
print(i)
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales)], data$Company.Sales[i+frequency(data$Company.Sales)]))
if (is.na(data$Company.Sales[i])==TRUE){
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales) ], data$Company.Sales[i-1 - frequency(data$Company.Sales)]))
}
}
}
lowerlimit <- quantile(data$Company.Sales,0.95)
upperlimit <- quantile(data$Company.Sales,0.05)
#We create a new vector that will hold the series we will create
n_data1 <- data$Company.Sales
#We now replace the values which are above and below the limits calculated earlier by the 95% and 5% quantiles.
n_data1[n_data1>lowerlimit] <- lowerlimit
n_data1[n_data1<upperlimit] <- upperlimit
plot(data$Company.Sales, type = "l", ylab = "Company sales", xlab = "year", main = "Company Sales")
lines(n_data1, col = "red")
legend("center", legend = c("Original", "Trimmed"),col, c("black","red"),lty=1)
# Coerce to Date class(it says double)
data$Date <- as.Date(data$Date , format = '%d-%m-%Y')
# Extract day of the week (Saturday = 6)
data$Week_Day <- as.numeric(format(data$Date, format='%w'))
# Adjust end-of-week date (first saturday from the original Date)
data$End_of_Week <- data$Date + (6 - data$Week_Day)
# Aggregate over week and climate division
weeklydata <- aggregate(data$Company.Sales~data$End_of_Week, FUN=mean, data=data, na.rm=TRUE)
#makemonthly
short.date = strftime(data$Date , "%Y/%m")
monthlydata = aggregate(data$Company.Sales ~ short.date, FUN = sum)
#rename
names(weeklydata)[names(weeklydata) == "data$End_of_Week"] <- "Endofweek"
names(weeklydata)[names(weeklydata) == "data$Company.Sales"] <- "weekly"
names(monthlydata)[names(monthlydata) == "short.date"] <- "Month"
names(monthlydata)[names(monthlydata) == "data$Company.Sales"] <- "monthlysales"
plot(data$Company.Sales, type = "l", ylab = "Company sales", xlab = "year", main = "Company Sales")
lines(n_data1, col = "red")
legend("center", legend = c("Original", "Trimmed"),col, c("black","red"),lty=1)
lowerlimit <- quantile(data$Company.Sales,0.95)
upperlimit <- quantile(data$Company.Sales,0.05)
#We create a new vector that will hold the series we will create
n_data1 <- data$Company.Sales
#We now replace the values which are above and below the limits calculated earlier by the 95% and 5% quantiles.
n_data1[n_data1>lowerlimit] <- lowerlimit
n_data1[n_data1<upperlimit] <- upperlimit
plot(data$Company.Sales, type = "l", ylab = "Company sales", xlab = "year", main = "Company Sales")
lines(n_data1, col = "red")
legend("center", legend = c("Original", "Trimmed"),col, c("black","red"),lty=1)
# Coerce to Date class(it says double)
data$Date <- as.Date(data$Date , format = '%d-%m-%Y')
# Extract day of the week (Saturday = 6)
data$Week_Day <- as.numeric(format(data$Date, format='%w'))
# Adjust end-of-week date (first saturday from the original Date)
data$End_of_Week <- data$Date + (6 - data$Week_Day)
# Aggregate over week and climate division
weeklydata <- aggregate(data$Company.Sales~data$End_of_Week, FUN=mean, data=data, na.rm=TRUE)
#makemonthly
short.date = strftime(data$Date , "%Y/%m")
monthlydata = aggregate(data$Company.Sales ~ short.date, FUN = sum)
#rename
names(weeklydata)[names(weeklydata) == "data$End_of_Week"] <- "Endofweek"
names(weeklydata)[names(weeklydata) == "data$Company.Sales"] <- "weekly"
names(monthlydata)[names(monthlydata) == "short.date"] <- "Month"
names(monthlydata)[names(monthlydata) == "data$Company.Sales"] <- "monthlysales"
for (i in (frequency(data$Company.Sales)+1): (length(data$Company.Sales)-12)){
if (is.na(data$Company.Sales[i])==TRUE){
print(i)
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales)], data$Company.Sales[i+frequency(data$Company.Sales)]))
if (is.na(data$Company.Sales[i])==TRUE){
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales) ], data$Company.Sales[i-1 - frequency(data$Company.Sales)]))
}
}
}
---
title: "Forecast_1"
author: "Diomides_Mavroyiannis"
date: "25/11/2020"
output: pdf_document
---
#Loading the data
```{r setup, include=FALSE}
data <- read.csv("C:/Users/DavidEttinger02/Desktop/Forecasting/Bi-weekly assignment data.csv")
#Preparing the library
library(forecast)
#Part A
```
# Visualize the Company sales column
```{r setup, include=TRUE}
plot(data$Company.Sales , type = "l", main = "Shopping", ylab = "Company.sales", xlab = "Date" )
```
#missing values
The approach here, is to check if a value is missing, if it is, then take the mean of the next and the previous period to fill it in. If the next slot is empty we simply take the average of two older slots
```{r setup, include=FALSE}
for (i in (frequency(data$Company.Sales)+1): (length(data$Company.Sales)-12)){
if (is.na(data$Company.Sales[i])==TRUE){
print(i)
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales)], data$Company.Sales[i+frequency(data$Company.Sales)]))
if (is.na(data$Company.Sales[i])==TRUE){
data$Company.Sales[i] <- mean(c(data$Company.Sales[i-frequency(data$Company.Sales) ], data$Company.Sales[i-1 - frequency(data$Company.Sales)]))
}
}
}
```
#outliers
We could reduce the effect of outlier by simply taking the log of the function but here we opt simply to change them to be closer to the other data.
#We first compute the values where 95% and 5% of the data is above that
```{r setup, include=FALSE}
lowerlimit <- quantile(data$Company.Sales,0.95)
upperlimit <- quantile(data$Company.Sales,0.05)
#We create a new vector that will hold the series we will create
n_data1 <- data$Company.Sales
#We now replace the values which are above and below the limits calculated earlier by the 95% and 5% quantiles.
n_data1[n_data1>lowerlimit] <- lowerlimit
n_data1[n_data1<upperlimit] <- upperlimit
```
```{r setup, include=TRUE}
plot(data$Company.Sales, type = "l", ylab = "Company sales", xlab = "year", main = "Company Sales")
lines(n_data1, col = "red")
legend("center", legend = c("Original", "Trimmed"),col, c("black","red"),lty=1)
```
#makeweekly
```{r setup, include=FALSE}
# Coerce to Date class(it says double)
data$Date <- as.Date(data$Date , format = '%d-%m-%Y')
# Extract day of the week (Saturday = 6)
data$Week_Day <- as.numeric(format(data$Date, format='%w'))
# Adjust end-of-week date (first saturday from the original Date)
data$End_of_Week <- data$Date + (6 - data$Week_Day)
# Aggregate over week and climate division
weeklydata <- aggregate(data$Company.Sales~data$End_of_Week, FUN=mean, data=data, na.rm=TRUE)
#makemonthly
short.date = strftime(data$Date , "%Y/%m")
monthlydata = aggregate(data$Company.Sales ~ short.date, FUN = sum)
#rename
names(weeklydata)[names(weeklydata) == "data$End_of_Week"] <- "Endofweek"
names(weeklydata)[names(weeklydata) == "data$Company.Sales"] <- "weekly"
names(monthlydata)[names(monthlydata) == "short.date"] <- "Month"
names(monthlydata)[names(monthlydata) == "data$Company.Sales"] <- "monthlysales"
```
#visualize monthly
```{r setup, include=TRUE}
plot(monthlydata$monthlysales , type = "l", main = "Monthly", ylab = "monthlysales", xlab = "Date" )
```
#visualize Weekly
```{r setup, include=TRUE}
plot(weeklydata$weekly , type = "l", main = "Weekly", ylab = "WeeklySales", xlab = "Date" )
```
```{r setup, include=FALSE}
#decompose monthly
TS <- ts(monthlydata$monthlysales, frequency = 12)
dec1 <- decompose(TS , type = "additive")
dec2 <- decompose(TS , type = "multiplicative")
```
```{r setup, include=TRUE}
plot(dec1, type = "l", ylab = "Index", xlab = "Period")
plot(dec2, type = "l", ylab = "Index", xlab = "Period")
```
As we can see, the main difference between the decomposition is the that the multiplicative decomposition reduces the magnitude of the random shock.
#Average
```{r setup, include=TRUE}
#The average daily sale is:
mean(data$Company.Sales)
#The average monthly sale is:
mean(monthlydata$monthlysales)
```
#Part B
```{r setup, include=TRUE}
#visualize
plot(data$Product.Sales , type = "l", main = "Shopping", ylab = "Product.sales", xlab = "Date" )
```
```{r setup, include=TRUE}
#Average Daily demand
mean(data$Product.Sales)
#Coefficient of Variation
sd(data$Product.Sales[0<data$Product.Sales])*100/mean(data$Product.Sales[0<data$Product.Sales])
```
```{r setup, include=TRUE}
#ADI
nonzero <- length(which(data$Product.Sales != 0))
zero <- length(which(data$Product.Sales != 0))
#the rate is:
rate <-zero/(nonzero+zero)
#So we inverse this to get the average expected days
Avgwait <- 1/rate
Avgwait
```
```{r setup, include=TRUE}
library(fpp)
```
```{r setup, include=TRUE}
plot(data$Product.Sales , type = "l", ylab = "Quantity", xlab = "days", main = "Sold product")
```
```{r setup, include=TRUE}
par(mfrow = c(1,3))
boxplot(data$Product.Sales, main = "Boxplot Quantity" )
hist(data$Product.Sales )
plot(density(data$Product.Sales), main = "Kernel Density of Quantity")
```
We can see the quantiles by looking at the density:
```{r setup, include=TRUE}
density(data$Product.Sales)
```
Or by computing them directly
```{r setup, include=TRUE}
quantile(data$Product.Sales,0.05)
quantile(data$Product.Sales,0.5)
quantile(data$Product.Sales,0.95)
```
Which makes sense, most of the data are zeros, so the 5% and the 50% are both zeros.
```{r setup, include=FALSE}
#makemonthly
qdate = strftime(data$Date , "%Y/%m")
qmonthlydata = aggregate(data$Product.Sales ~ qdate, FUN = sum)
#rename
names(qmonthlydata)[names(qmonthlydata) == "qdate"] <- "Month"
names(qmonthlydata)[names(qmonthlydata) == "data$Product.Sales"] <- "monthlysales"
```
```{r setup, include=TRUE}
#visualize monthly
plot(qmonthlydata$monthlysales , type = "l", main = "Monthly", ylab = "monthlysales", xlab = "Date" )
```
```{r setup, include=TRUE}
#decompose monthly
TS <- ts(qmonthlydata$monthlysales, frequency = 12)
dec <- decompose(TS , type = "additive")
#dec <- decompose(TS , type = c("additive", "multiplicative"))
plot(dec, type = "l", ylab = "Index", xlab = "Period")
```
It appears like the trend is that 2 small spikes and one big one every 12 months. Checking this effect manually confirms the intuition that it must be Christmas
knitr::opts_chunk$set(echo = TRUE)
